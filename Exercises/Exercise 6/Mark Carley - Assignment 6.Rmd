---
title: "Data Visualisation 2019 - Assignment 6 - Mark Carley -20071864"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---



## List of R colors:
http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf


# Time Series

* The basic idea behind time series is that we use the past behavior of a variable to predict its future values.

* Time series arise in a vast verity of circumstances, including but not limited to:
    
    * Daily closing stock prices
    * Daily relative values of currencies
    * Monthly unemployment rates in a country
    * Quarterly public debt levels in a country
    * Weekly viewership figures of a TV series
    * Average annual CO2 emissions
    * Quarterly sales figures of a retailer
    * Monthly production figures of a factory
    * Annual % growth of GDP of an economy
    * etc. etc. etc.
    
## Example 1 

To gain an better understanding of how time series operate, we will examine the monthly sales figures for a mobile phone __Model M__ sold by a particular retailer. The monthly sales figures over a 24 month period are given in the table below:

|  Month  | Monthly Sales Figures (Year 1) | Monthly Sales Figures (Year 2)  |
|---------|--------------------------------|---------------------------------|
|   Jan   |               197              |             296                 |
|   Feb   |               211              |             276                 |
|   Mar   |               203              |             305                 |
|   Apr   |               247              |             308                 |
|   May   |               239              |             356                 |
|   Jun   |               269              |             393                 |
|   Jul   |               308              |             363                 |
|   Aug   |               262              |             386                 |
|   Sep   |               258              |             443                 |
|   Oct   |               256              |             308                 |
|   Nov   |               261              |             358                 |
|   Dec   |               288              |             384                 |

* To begin the times series analysis of this data, we create a data vector __MS__ (Monthly Sales) to contain the sales data:
```{r}
MS<-c(197,211,203,247,239,269,308,262,258,256,261,288,296,276,305,308,356,393,363,386,443,308,358,384)
MS
length(MS)
```
*Next we need to create a _time vector_ against which these sales figures are plotted:
    * We need a vector with the same length as __MS__, i.e. with 24 entries, starting at 1 and increasing        in increments of 1.
    * We can automate a lot of this for future examples using the __length()__ and __seq()__ functions
```{r}
Time <- seq(1,length(MS),1)
Time
length(Time)
```
* This creates a sequence of values starting at 1, ending at __length(MS)__ and increasing with a step-size 1.

* __Time__ and __MS__ now both have 24 entries, so we can plot them on the same graph:
```{r}
plot(Time,MS,pch=15,col="red",ylab="Monthly Sales Figures", xlab="Month",main="Monthly Sales Figures of Phone Model M")
lines(Time,MS)
```
* The function __lines()__ indicates that a line should be drawn between each of the data points of the time series. 
* Recall that the argument __pch__ appearing in __plot()__ selects the type of marker used to mark the data points.  Its possible values are 1 to 26.

## Forecasting
* Recall from lectures that we used a __linear regression model__ to model the data in this time series. This model was given by
\[
\hat{y}_t=198.03+8.07t
\]
where $t$ referred to a month number.

* We will now create our own __R function__ corresponding to this, which we are going to call __Forecast1__

```{r}
Forecast1 <- function(t){
  198.03+8.07*t
}
```
* The values predicted by this model at each of the months in __Time__ are now given by
```{r}
Forecast1(Time)
```
## Mean Absolute Deviation (MAD) & Mean Square Error (MSE)
* Recall that the __Mean Absolute Deviation__  (__MAD__) of a model, was given by

\[
MAD= \frac{1}{n}\sum_{t=1}^{N}\vert y_{t}-\hat{y}_t\vert
\]
    
  * $y_t$ denotes the actual value of the variable $y$ at time $t$
  * $\hat{y}_t$ denotes the predicted value of the variable $y$ at time $t$
  * $n$ is the number of observations we have, i.e. the number of actual values $y_t$.
  * __R__ will calculate this for us automatically as follows:
```{r}
MAD1<-mean(abs(MS-Forecast1(Time)))
MAD1
```
* The code and the formula correspond as follows

    1. __MS__ $\leftrightarrow y_t$, 
    
    2. __Forecast(Time)__ $\leftrightarrow \hat{y}_t$
    
    3. __abs(MS-Forecast1(Time))__ $\leftrightarrow \vert y_t-\hat{y}_t\vert$
    
    4. __mean(abs(MS-Forecast1(Time)))__ $\leftrightarrow \frac{1}{n}\sum_{t=1}^{n}\vert y_t-\hat{y}_t\vert$

* Recall also that the __Mean Square Error__  (__MSE__) of a model is given by
\[
MSE=\frac{1}{n}\sum_{t=1}^{n}\vert y_t-\hat{y}_t\vert^2
\]

## Exercise 1

Modify this code block to find the __MSE__ of the model. 

```{r}
MSE1<-mean(abs(MS-Forecast1(Time))^2)
MSE1
```


# Prediction Intervals
* We can also use the model to forecast future sales values of phone model M.

* To find the __90% Prediction Interval__ of the model at month 27 say, we can use thee following formula for this interval
\[
  \hat{y}_{x^{*}}\pm t_{\frac{\alpha}{2},n-2}\sqrt{MSE\left(1+\frac{1}{n}+\frac{x^{*}-\bar{x}}{\sum_{i=1}^{n}(x_i-\bar{x})^2}\right)}
\]
* The symbols in the formula have the following meaning
    1. $x^{*}=27$, the month number we want to predict sales figures for
    2. $\hat{y}_{x^{*}} = \hat{y}_{27}$, the predicted sales for month 27
    3. $\alpha = 1-\frac{90}{100}=0.1$, the confidence parameter fro the 90% Prediction Interval
    4. $n=24$, the number of actual data values we have
    6. $n-2$ the number of __degrees of freedom (df)__ used 
    7. $t_{\frac{\alpha}{2},n-2}$, the critical $t$-value given these parameters
    8. $MSE$ the mean square error of the model
    9. $\bar{x}$ the mean month number, in this case $\bar{x}=\frac{1}{24}\sum_{i=1}^{24}i = \frac{1+2+\ldots+24}{24}$
* To find the critical value

$t_{\frac{\alpha}{2},n-2}$ we us the 
```{r}
t_star = abs(qt(0.05,df=22)) # df= Number of months-2
```
$x^*$
```{r}
x_star=27
```

$y^*$

```{r}
y_star=Forecast1(27)
y_star
```
MSE
```{r}
MSE1
```

$\bar{x}$

```{r}
x_bar=mean(Time)
```

$\Sigma_{i=1}^{n}(x_i-\bar{x})^2$
```{r}
Sum1=sum((Time-x_bar)^2)
```

### Upper boundary of CI

```{r}
y_star+t_star*sqrt(MSE1*(1+1/24+(x_star-x_bar)/Sum1))
```
### Lower boundary of CI

```{r}
y_star-t_star*sqrt(MSE1*(1+1/24+(x_star-x_bar)/Sum1))
```

## The 90% Prediction Interval
We are 90% confident that sales in the 27th month will be between 362 and 469 units. 



# Exercise 2
Find the 90% prediction interval for sales in the 27th month.



# Exercise 3

The closing values of Apple Inc. (AAPL) Stock on the NASDAQ Stock Exchange from 8 August 2017 to 8 November 2017 are given in the data file __AppleQuotes(3M).csv__, available on Moodle.
(Available at http://www.nasdaq.com)


Using this data set answer the following:

1. Import the data in this file using the following and call the data structure __AAPL__
```{r}
AAPL<-read.csv('AppleQuotes(3M).csv')
```
2. Create __two__ data vectors from this file, one for the __closing value__ and one for the __day__

```{r}
Clo<-AAPL$close
Day<-AAPL$day
```
3. Create a time series plot for this data.

4. From this data plot, determine if there is a trend in the closing value of Apple stock over the past 3 months.

5. Use the function __lm(Closing Value ~ Day)__ to create a linear regression model for this data.

6. Create a linear model to forecast this data.

7. Create an __R__ function to represent this model.

8. Find the MAD and MSE of this model
Forcast values


9. Find the 95% prediction interval for the closing price of Apple Stock in 10 days from now.

----------------------------------------------------------------------------------------------------------------------

Exercises 3 solutions

1. 
```{r}
AAPL<-read.csv('AppleQuotes(3M).csv')
```

2.

```{r}
CD<-c(176.24,174.81,174.25,172.5,168.11,166.89,169.04,166.72,163.05,157.41,156.41,157.1,156.17,156.25,155.98,159.76,160.47,159.88,156.99,156,156.55,155.9,155.84,155.3,155.39,153.48,154.48,153.81,154.12,153.28,154.23,153.14,150.55,151.89,153.39,156.07,158.73,158.67,159.88,158.28,159.65,160.86,161.5,158.63,161.26,161.91,162.08,164.05,164,163.35,162.91,161.47,159.86,159.27,159.98,159.78,157.21,157.5,157.86,160.95,161.6,159.85,157.48,155.32,161.06,160.08)
CD
length(CD)
```


```{r}
DD<-c(66,65,64,63,62,61,60,59,58,57,56,55,54,53,52,51,50,49,48,47,46,45,44,43,42,41,40,39,38,37,36,35,34,33,32,31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
DD
length(DD)
```



3.

```{r}
Time1 <- seq(1,length(CD),1)
Time1
length(Time1)
```



```{r}
plot(Time1,CD,pch=15,col="red",ylab="Apple Value stock", xlab="Month",main="Monthly stats figures")
lines(Time1,DD)

```

4.

From examining the plot diagram, there seems to be steap rises on day 18, 50 and 60 in stock levels.

5.

```{r}
lm(Clo~Day)
```

6.

\\[y=157+0.75t\\]

7.

```{r}
AAPL_Forecast <- function(t){
  157.12+0.075*t
}
```

8.

```{r}
Forecasts<-AAPL_Forecast(Day)
Forecasts
```


// MAD AND MSE FOR CLOSING
```{r}
MAD2<-mean(abs(CD-AAPL_Forecast(Time1)))
MAD2
```

```{r}
MSE2<-mean(abs(CD-AAPL_Forecast(Time1))^2)
MSE2
```

//MAD AND MSE FOR DAY
```{r}
MAD3<-mean(abs(DD-AAPL_Forecast(Time1)))
MAD3
```

```{r}
MSE3<-mean(abs(DD-AAPL_Forecast(Time1))^2)
MSE3
```

9.

```{r}
t_star1 = abs(qt(0.025,df=64))
```

```{r}
x_star1=76
```
// ten days ahead of maximum value


```{r}
y_star1=AAPL_Forecast(76)
y_star1
```

```{r}
MSE2
```

```{r}
x_bar1=mean(Time1)
```

```{r}
Sum2=sum((Time1-x_bar)^2)
```

```{r}
y_star1+t_star1*sqrt(MSE2*(1+1/66+(x_star1-x_bar1)/Sum2))
```

```{r}
y_star1-t_star1*sqrt(MSE2*(1+1/66+(x_star1-x_bar1)/Sum2))
```

95% confident that values are between 172.73 and 152.90.

# Exercise 4

The closing values of Google Inc. (GOOGL) Stock on the NASDAQ Stock Exchange from 8 November 2016 to 8 November 2017 are given in the data file __GoogleQuotes(3M).csv__, available on Moodle .
(Available at http://www.nasdaq.com).


Using this data set answer the following:

1. Import the data in this file using the following and call the data structure __GOOGL__

2. Create __two__ data vectors from this file, one for the __trading value__ and one for the __day__

3. Create a time series plot for this data.

4. From this data plot, determine if there is a trend in the closing value of Google stock over the past year.

5. Use the function __lm(Trading Value ~ Day)__ to create a linear regression model for this data.

6. Create a linear model to forecast this data.

7. Create an __R__ function to represent this model.

8. Find the __MAD__ and __MSE__ of this model

9. Find the 90% and 99% prediction intervals for the  trading volume of Google Stock in 10 days from now.

----------------------------------------------------------------------------------------------------------------------

1.
```{r}
GOOGL<-read.csv('GoogleQuotes(1Y).csv')
```

2.
```{r}
DD1<-c(253,252,251,250,249,248,247,246,245,244,243,242,241,240,239,238,237,236,235,234,233,232,231,230,229,228,227,226,225,224,223,222,221,220,219,218,217,216,215,214,213,212,211,210,209,208,207,206,205,204,203,202,201,200,199,198,197,196,195,194,193,192,191,190,189,188,187,186,185,184,183,182,181,180,179,178,177,176,175,174,173,172,171,170,169,168,167,166,165,164,163,162,161,160,159,158,157,156,155,154,153,152,151,150,149,148,147,146,145,144,143,142,141,140,139,138,137,136,135,134,133,132,131,130,129,128,127,126,125,124,123,122,121,120,119,118,117,116,115,114,113,112,111,110,109,108,107,106,105,104,103,102,101,100,99,98,97,96,95,94,93,92,91,90,89,88,87,86,85,84,83,82,81,80,79,78,77,76,75,74,73,72,71,70,69,68,67,66,65,64,63,62,61,60,59,58,57,56,55,54,53,52,51,50,49,48,47,46,45,44,43,42,41,40,39,38,37,36,35,34,33,32,31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)
DD1
length(DD1)
```

```{r}
TD1<-c(1058.29,1052.39,1042.68,1049.99,1042.97,1042.595,1033.04,1033.13,1033.67,991.42,991.46,988.49,985.54,1005.07,1001.84,1012.74,1011,1009.35,1007.87,1005.65,1005.65,987.8,992.31,993.64,985.19,966.78,972.08,967.47,973.72,964.81,959.9,937.43,934.28,943.26,947.55,947.54,936.86,929.75,935.29,940.13,950.44,946.65,943.29,941.41,949.89,942.02,941.48,951.99,955.24,943.63,935.75,928.13,930.5,936.89,942.58,940.4,920.87,926.18,927.66,944.27,938.08,938.93,930.09,923.59,940.08,944.19,945.75,945.79,940.3,947.64,946.56,945.5,958.33,952.51,965.31,969.03,998.31,993.84,992.19,992.77,986.95,975.96,976.91,968.85,967.66,953.53,951,940.81,927.69,932.26,919.46,929.68,937.82,961.01,948.09,972.09,986.09,976.62,978.59,968.99,975.22,958.62,960.18,967.93,970.5,961.81,970.12,1004.28,1001.59,996.68,1003.88,996.12,988.29,987.09,996.17,993.27,991.86,977.61,970.55,964.07,954.65,950.5,942.17,964.61,959.22,955.14,955.89,954.84,956.71,958.69,950.28,954.72,948.45,937.09,932.82,924.52,891.44,889.14,888.84,878.93,858.95,860.08,856.51,853.99,855.13,840.18,841.46,839.88,841.7,842.1,845.095,848.91,852.57,856.75,847.8,849.48,849.87,840.63,838.51,835.14,839.65,849.8,850.14,867.91,872.37,870,868.39,865.91,864.58,861.405,857.84,853.64,851.15,847.27,849.08,849.85,856.75,844.93,849.67,847.81,851,851.36,849.27,846.55,842.17,837.32,840.03,838.96,834.85,830.06,829.88,829.23,821.62,820.13,818.26,815.24,820.19,823.83,845.03,856.98,858.45,849.53,844.43,828.17,824.37,829.02,827.46,830.94,829.53,829.86,826.01,827.18,825.21,813.02,807.77,808.01,792.45,802.88,804.57,809.93,807.8,809.68,812.2,815.2,812.5,809.84,815.65,817.89,815.34,807.9,809.45,795.17,791.47,776.18,778.22,764.46,764.33,775.88,789.44,785.79,780.23,779,785,784.8,775.97,786.16,779.98,775.16,753.22,771.75,780.29,805.59,811.98)
TD1
length(TD1)

```

```{r}
Closing<-GOOGL$close
Days<-GOOGL$day
```


3.

```{r}
Time2 <- seq(1,length(TD1),1)
Time2
length(Time2)
```


```{r}
plot(Time2,TD1,pch=15,col="red",ylab="Google stock exchange value", xlab="Days passed",main="Daily stock figures")
lines(Time2,DD1)

```


4.

From looking at the data, there seems to be rapid declines in stock value at day 38, 75, and 125 while have slightly
steep rises on day 200 and day 250.

5.


```{r}
lm(Closing~Days)
```

6.

\\[y=783+0.938t\\]

7.


```{r}
GOOGL_Forecast <- function(t){
  783.79+0.093*t
}
```

8.


```{r}
Forecasts1<-GOOGL_Forecast(Days)
Forecasts1
```


// MAD AND MSE FOR CLOSING
```{r}
MAD4<-mean(abs(TD1-GOOGL_Forecast(Time2)))
MAD4
```

```{r}
MSE4<-mean(abs(TD1-GOOGL_Forecast(Time2))^2)
MSE4
```

//MAD AND MSE FOR DAY
```{r}
MAD5<-mean(abs(DD1-GOOGL_Forecast(Time2)))
MAD5
```

```{r}
MSE5<-mean(abs(DD1-GOOGL_Forecast(Time2))^2)
MSE5
```


9.

//90% PREDICTION


```{r}
t_star2 = abs(qt(0.05,df=251))
```


```{r}
x_star2=263
```

```{r}
y_star2=GOOGL_Forecast(263)
y_star2
```

```{r}
MSE4
```

```{r}
x_bar2=mean(Time2)
```

```{r}
Sum3=sum((Time2-x_bar2)^2)
```

```{r}
y_star2+t_star2*sqrt(MSE4*(1+1/253+(x_star2-x_bar2)/Sum3))
```

```{r}
y_star2-t_star2*sqrt(MSE4*(1+1/253+(x_star2-x_bar2)/Sum3))
```

/// 90% PREDICTION LIES BETWEEN 584.99 TO 1031.50.


```{r}
t_star3 = abs(qt(0.010,df=251))
```

```{r}
y_star2+t_star3*sqrt(MSE4*(1+1/253+(x_star2-x_bar2)/Sum3))
```

```{r}
y_star2-t_star3*sqrt(MSE4*(1+1/253+(x_star2-x_bar2)/Sum3))
```

/// 99% PREDICTION LIES BETWEEN 491.63 TO 1124.85



# Exercise 5

The % Growth in GDP of Chin, the UK, the US, Ireland, the EU, the OECD and the World, for the years 1961-2016 are given in the data file __RegionalGDPGrowth(1961-2016).csv__. Import this data file into __R__ and answer the following questions. 
(Available at http://www.worldbank.org)


1. Create a data vector for the __Year__  a separate vector for the GDP growth of each country in the data file.

2. Use the function __par(mfrow=c(A,B))__ to create a collection of time-series plots in __A=1__ row and __B=2__ columns for the GDP growth of China and the US
 To illustrate how this function works, the time-series plot from __Example 1__ is plotted in __1__ row and __2__ columns  
```{r}
par(mfrow=c(1,2))
plot(Time,MS,pch=15,col="red",ylab="Monthly Sales Figures", xlab="Month",main="Monthly Sales Figures of Phone Model M")
lines(Time,MS)
plot(Time,MS,pch=15,col="red",ylab="Monthly Sales Figures", xlab="Month",main="Monthly Sales Figures of Phone Model M")
lines(Time,MS)
```
3. Use the function __par(mfrow=c(A,B))__ to create a collection of time-series plots in __A=3__ row and __B=1__ columns for the GDP growth of China and the US, the UK

 
4. Use the function __par(mfrow=c(A,B))__ to create a collection of time-series plots in __A=2__ row and __B=2__ columns for the GDP growth of the EU, the US, the OECD and the World.

5. Is there any apparent trend in economic growth observable from these time-series.

6. From the time-series plots, which region has shown the most consistent economic growth between 1961 and 2016.


---------------------------------------------------------------------------------------------------------------------

1.

```{r}
GDPYear<-c(1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016)
GDPYear
length(GDPYear)
```

```{r}
GDPChina<-c(-27.27,-5.58,10.3,18.18,16.95,10.65,-5.77,-4.1,16.94,19.3,7.06,3.81,7.76,2.31,8.72,-1.57,7.57,11.667,7.6,7.807,5.172,8.934,10.835,15.139,13.443,8.94,11.689,11.235,4.186,3.907,9.294,14.216,13.868,13.052,10.949,9.928,9.231,7.838,7.667,8.492,8.34,9.131,10.036,10.111,11.396,12.719,14.231,9.654,9.4,10.636,9.536,7.856,7.758,7.298,6.9,6.7)
GDPChina
length(GDPChina)
```

```{r}
GDPUK<-c(2.574,1.328,3.956,5.038,2.789,2.049,2.311,3.985,2.052,5.958,3.479,4.294,6.516,-2.473,-1.488,2.922,2.463,4.195,3.735,-2.041,-0.779,2.016,4.221,2.275,4.187,3.153,5.359,5.787,2.583,0.717,-1.119,0.36,2.507,3.885,2.506,2.549,3.127,3.191,3.283,3.745,2.726,2.397,3.466,2.528,2.972,2.503,2.556,-0.627,-4.328,1.915,1.509,1.313,1.911,3.07,2.194,1.806)
GDPUK
length(GDPUK)
```

```{r}
GDPIre<-c(0,0,0,0,0,0,0,0,0,0,3.47,6.49,4.721,4.26,5.657,1.395,8.211,7.187,3.073,3.079,3.325,2.283,-0.244,4.354,3.086,-0.428,4.663,5.217,5.814,8.467,1.93,3.343,2.693,5.756,9.634,9.092,10.747,8.228,10.863,9.912,6.052,5.577,3.673,6.725,5.766,5.866,3.797,-4.373,-4.565,2.034,-0.041,-1.103,1.099,8.462,26.276,5.214)
GDPIre
length(GDPIre)
```

```{r}
GDPOC<-c(4.719,5.852,5.373,6.577,5.53,6.134,4.582,6.171,5.719,3.605,3.798,5.511,6.158,1.115,0.366,4.843,3.74,4.393,3.981,1.346,2.132,0.274,2.766,4.611,3.931,2.964,3.451,4.686,3.913,3.181,1.347,2.032,1.352,3.04,2.716,3.052,3.404,2.78,3.24,4.019,1.374,1.557,1.969,3.199,2.706,2.957,2.525,0.182,-3.54,2.889,1.796,1.242,1.408,1.946,2.254,1.733)
GDPOC
length(GDPOC)
```

```{r}
GDPUS<-c(2.3,6.1,4.4,5.8,6.4,6.5,2.5,4.8,3.1,3.207,3.295,5.263,5.643,-0.517,-0.198,5.386,4.609,5.562,3.176,-0.245,2.594,-1.911,4.632,7.259,4.239,3.512,3.462,4.204,3.681,1.919,-0.074,3.555,2.746,4.038,2.719,3.796,4.487,4.45,4.685,4.092,0.976,1.786,2.807,3.786,3.345,2.667,1.779,-0.292,-2.776,2.532,1.601,2.224,1.677,2.37,2.596,1.616)
GDPUS
length(GDPUS)
```

```{r}
GDPWorld<-c(4.324,5.559,5.21,6.662,5.552,5.789,4.415,6.183,6.118,4.628,4.317,5.756,6.536,1.99,0.774,5.359,4.019,4.011,4.164,1.99,1.929,0.342,2.394,4.539,3.868,3.322,3.58,4.654,3.752,3.002,1.421,1.778,1.632,3.01,3.049,3.385,3.67,2.524,3.261,4.399,1.941,2.144,2.915,4.453,3.846,4.326,4.256,1.819,-1.735,4.327,3.156,2.439,2.601,2.831,2.734,2.438)
GDPWorld
length(GDPWorld)
```

```{r}
GDPEU<-c(5.592,5.031,5.148,5.568,4.393,4.299,4.456,5.064,5.787,5.609,3.64,4.715,6.105,2.224,-0.779,4.599,2.814,3.225,3.831,1.47,0.32,0.986,1.835,2.454,2.614,2.671,2.945,4.409,3.725,2.971,1.425,1.058,-0.151,2.837,2.687,1.997,2.773,2.977,3.033,3.881,2.236,1.337,1.334,2.594,2.084,3.358,3.086,0.458,-4.383,2.153,1.666,-0.472,0.222,1.67,2.203,1.874)
GDPEU
length(GDPEU)
```

2.


```{r}
Time10 <- seq(1,length(GDPChina),1)
Time10
length(Time10)
```


```{r}
Time11 <- seq(1,length(GDPUS),1)
Time11
length(Time11)
```

```{r}
par(mfrow=c(1,2))
plot(Time10,GDPChina,pch=15,col="red",ylab="Value of GDP", xlab="Month",main="GDP OF CHINA")
lines(Time10,GDPChina)
plot(Time11,GDPUS,pch=15,col="blue",ylab="Value of GDP", xlab="Month",main="GDP OF USA")
lines(Time11,GDPUS)
```


3.


```{r}
Time12 <- seq(1,length(GDPUK),1)
Time12
length(Time12)
```

```{r}
par(mfrow=c(1,2))
plot(Time10,GDPChina,pch=15,col="red",ylab="Value of GDP", xlab="Month",main="GDP OF CHINA")
lines(Time10,GDPChina)
plot(Time11,GDPUS,pch=15,col="blue",ylab="Value of GDP", xlab="Month",main="GDP OF USA")
lines(Time11,GDPUS)
plot(Time12,GDPUK,pch=15,col="orange",ylab="Value of GDP", xlab="Month",main="GDP OF UK")
lines(Time12,GDPUK)

```


4.

```{r}
Time13 <- seq(1,length(GDPEU),1)
Time13
length(Time13)
```

```{r}
Time14 <- seq(1,length(GDPOC),1)
Time14
length(Time14)
```

```{r}
Time15 <- seq(1,length(GDPWorld),1)
Time15
length(Time15)
```


```{r}
par(mfrow=c(1,2))
plot(Time13,GDPEU,pch=15,col="red",ylab="Value of GDP", xlab="Month",main="GDP OF EUROPEAN UNION")
lines(Time13,GDPEU)
plot(Time11,GDPUS,pch=15,col="blue",ylab="Value of GDP", xlab="Month",main="GDP OF USA")
lines(Time11,GDPUS)
plot(Time14,GDPOC,pch=15,col="orange",ylab="Value of GDP", xlab="Month",main="GDP OF OECD")
lines(Time14,GDPOC)
plot(Time15,GDPWorld,pch=15,col="purple",ylab="Value of GDP", xlab="Month",main="GDP OF THE WORLD")
lines(Time15,GDPWorld)
```


5.

ALL the GDP value of each region seems to drop rapidly near the 2000 to 2016 years.

6.

From looking at the graphs, China has shown the best economic growth out of all sectors.





